{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ZROS: A fast, lightweight ROS-like library","text":"<p>ZROS is a fast, lightweight ROS-like library designed to bring the ease of ROS-2 to Python projects that require minimal overhead and high performance, using ZeroMQ for fast, asynchronous communication.</p> <p>It provides a simple, pure Python alternative for robotic applications, computer vision pipelines, and distributed systems where a full ROS installation might be overkill.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Fast &amp; Lightweight: Built on top of ZeroMQ, ensuring low-latency communication between nodes.</li> <li>ROS-like API: Uses familiar concepts like <code>Node</code>, <code>Publisher</code>, <code>Subscriber</code>, <code>Timer</code>, and <code>spin()</code> making it easy for ROS-2 developers to adapt.</li> <li>No Complex Build System: Pure Python. No <code>catkin_make</code>, no <code>colcon build</code>, no <code>source setup.bash</code>. Just run your Python scripts.</li> <li>Computer Vision Ready: Includes a built-in <code>zCvBridge</code> for seamless OpenCV image transport, and <code>zCompressedCVBridge</code> which can optimize bandwidth usage up to 30x during transmission.</li> <li>Bridge Legacy and Modern Environments: Build hybrid architectures spanning Python 3.8 and Python 3.12+ gracefully over <code>localhost</code>.</li> </ul>"},{"location":"#why-zros-bridging-legacy-and-modern-robotics","title":"Why ZROS? Bridging Legacy and Modern Robotics","text":"<p>A major hurdle in modern robotics research is the software gap between established frameworks and cutting-edge AI.</p> <p>Projects using robust legacy systems like ROS1 Noetic are strictly tied to Python 3.8 and specific OS/hardware driver stacks. However, integrating state-of-the-art AI tools like SAM3 (Segment Anything) requires modern Python 3.10+, updated PyTorch versions, and fresh dependencies.</p> <p>Traditional workarounds fall short:</p> <ul> <li>Installing new ML libraries into a legacy <code>catkin_ws</code> almost always breaks the system with dependency hell.</li> <li>Using Docker introduces friction: passing through physical GPUs/cameras is unreliable, networking ROS topics across container boundaries is tedious, and rebuilding containers ruins rapid prototyping.</li> </ul> <p>The ZROS + <code>uv</code> Solution: Run your hardware and control loops in their native ROS1 environment. Run your modern AI models in completely isolated, modern Python virtual environments managed by <code>uv</code>. ZROS connects them instantly. </p> <p>Example Usage: <pre><code>sjmp@pc:~$ rostopic pub -1 /detect_object/prompt std_msgs/String \"data: 'hand'\"\n</code></pre> SAM3 Object Detection in ROS Noetic: </p> <p>Read the full guide on Bridging Systems in the documentation.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi-recommended","title":"From PyPI (Recommended)","text":"<pre><code>uv venv\n# For basic ZROS (no computer vision features):\nuv pip install zros\n\n# To include OpenCV and Numpy for image transport:\nuv pip install zros[cv2]\n</code></pre>"},{"location":"#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/juliodltv/zros.git\ncd zros\nuv sync # Add --extra cv2 for image transport support\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#create-a-publisher-publisherpy","title":"Create a Publisher (publisher.py)","text":"<pre><code>from zros import zNode, zCompressedCVBridge\nimport cv2\n\nclass CameraPublisher(zNode):\n    def __init__(self):\n        super().__init__(\"camera_pub\")\n        self.pub = self.create_publisher(\"video_topic\")\n        self.bridge = zCompressedCVBridge()\n        self.cap = cv2.VideoCapture(0)\n        self.create_timer(1/60, self.timer_callback)\n\n    def timer_callback(self):\n        ret, frame = self.cap.read()\n        if ret:\n            # msg is a dictionary\n            msg = {\n                \"zimgmsg\": self.bridge.cv2_to_zimgmsg(frame),\n                \"info\": \"My Camera Frame\"\n            }\n            self.pub.publish(msg)\n\nif __name__ == \"__main__\":\n    CameraPublisher().spin()\n</code></pre>"},{"location":"#create-a-subscriber-subscriberpy","title":"Create a Subscriber (subscriber.py)","text":"<pre><code>from zros import zNode, zCompressedCVBridge\nimport cv2\n\nclass VideoSubscriber(zNode):\n    def __init__(self):\n        super().__init__(\"video_sub\")\n        self.bridge = zCompressedCVBridge()\n        self.create_subscriber(\"video_topic\", self.callback)\n\n    def callback(self, msg):\n        img = self.bridge.zimgmsg_to_cv2(msg[\"zimgmsg\"])\n        # info = msg[\"info\"]\n        # print(info)\n        cv2.imshow(\"Video\", img)\n        cv2.waitKey(1)\n\nif __name__ == \"__main__\":\n    VideoSubscriber().spin()\n</code></pre>"},{"location":"#running-examples","title":"Running Examples","text":"<p>You can find another examples in the <code>examples/</code> directory.</p> <pre><code># Terminal 1\nuv run zroscore\n\n# Terminal 2\nuv run publisher.py\n\n# Terminal 3\nuv run subscriber.py\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>For detailed usage instructions, please refer to the ZROS Documentation.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@software{zros2026,\n  author = {Julio De La Torre-Vanegas},\n  title = {ZROS: A fast, lightweight ZeroMQ ROS-like library},\n  year = {2026},\n  url = {https://github.com/juliodltv/zros}\n}\n</code></pre>"},{"location":"about/","title":"About","text":""},{"location":"about/#citation","title":"Citation","text":"<p>If you use ZROS in your research or project, please cite it:</p> <pre><code>@software{zros2026,\n  author = {Julio De La Torre-Vanegas},\n  title = {ZROS: A fast, lightweight ZeroMQ ROS-like library},\n  year = {2026},\n  url = {https://github.com/juliodltv/zros}\n}\n</code></pre>"},{"location":"about/#license","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2025 ZROS\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"bridge_case/","title":"Bridging Legacy and Modern Systems (ROS1 &amp; SAM3)","text":"<p>Many robotics projects face a common dilemma: the need to integrate state-of-the-art AI models with legacy hardware and software systems. </p> <p>A classic example is using <code>ROS1 Noetic</code>, a robust framework that is often deeply tied to specific operating systems (like Ubuntu 20.04), older Python versions (Python 3.8), and hardware drivers that cannot be easily updated or migrated. On the other hand, modern AI tools like <code>Segment Anything Model 3</code> require modern Python environments, modern PyTorch installations, and newer dependencies.</p> <p>Trying to install these modern tools into a legacy ROS1 environment usually results in dependency conflicts, broken packages, or simply unsupported library versions.</p>"},{"location":"bridge_case/#the-problem-with-other-solutions","title":"The Problem with Other Solutions","text":""},{"location":"bridge_case/#why-not-just-use-docker","title":"Why not just use Docker?","text":"<p>While Docker is a great tool for isolation, it introduces significant friction in a robotics development workflow:</p> <ol> <li>Hardware Passthrough Complexity: Exposing GPUs, cameras, and specialized serial devices to a container can be tedious and sometimes unreliable.</li> <li>Network Overhead: Configuring ROS networking (<code>ROS_MASTER_URI</code>, <code>ROS_IP</code>) across container boundaries adds unnecessary complexity.</li> <li>Development Cycle: Rebuilding containers for every minor code change slows down rapid prototyping and debugging.</li> </ol>"},{"location":"bridge_case/#the-zros-uv-solution","title":"The ZROS + uv Solution","text":"<p>By combining ZROS with a modern Python package manager like uv, you can create a seamless, high-performance bridge between these two isolated environments on the same machine\u2014without the overhead of Docker.</p>"},{"location":"bridge_case/#how-it-works","title":"How it works","text":"<ol> <li>The Legacy Node (ROS1): Your main control loop, camera drivers, and hardware interfaces continue running in their native, unchanged ROS1 environment.</li> <li>The Modern Node (SAM3): Your cutting-edge AI model runs in a completely isolated, modern Python virtual environment managed by <code>uv</code>.</li> <li>The Bridge (ZROS): Both sides communicate asynchronously over <code>localhost</code> using ZROS.</li> </ol> <p>Placeholder: Image Diagram of the architecture</p>"},{"location":"bridge_case/#example-object-detection-bridge","title":"Example: Object Detection Bridge","text":"<p>Below is a real-world example of how to implement this architecture.</p>"},{"location":"bridge_case/#1-the-legacy-side-ros1-node","title":"1. The Legacy Side (ROS1 Node)","text":"<p>This script runs in the system's ROS1 environment (e.g., Python 3.8). It subscribes to a ROS camera topic, receives a text prompt, and publishes the data via ZROS to the modern environment. When the modern environment replies with a segmentation mask, it converts it back to a standard ROS <code>Image</code> message.</p> scripts/detect_object.py<pre><code>#!/usr/bin/env python3\nimport rospy\nimport numpy as np\nimport threading\nimport subprocess\n\nfrom sensor_msgs.msg import Image\nfrom std_msgs.msg import String\nfrom cv_bridge import CvBridge\n\n# Import ZROS into the legacy environment\nfrom zros import zNode, zCompressedCVBridge\n\nclass DetectObjects:\n    def __init__(self):\n        rospy.init_node('detect_objects_node')\n\n        # ROS 1 Setup\n        self.cv_bridge = CvBridge()\n        self.current_frame = None\n        self.current_header = None\n\n        rospy.Subscriber('/detect_object/prompt', String, self.prompt_callback)\n        rospy.Subscriber(\"/rgb/image_raw\", Image, self.image_callback)\n        self.mask_object_pub = rospy.Publisher(\"/mask/object\", Image, queue_size=1)\n        self.mask_objects_pub = rospy.Publisher(\"/mask/objects\", Image, queue_size=1)\n\n        # ZROS Setup (The Bridge)\n        self.znode = zNode(\"ros_sam3\")\n        self.zcv_bridge = zCompressedCVBridge()\n        self.z_pub = self.znode.create_publisher(\"sam3_bridge/ros\")\n        self.znode.create_subscriber(\"sam3_bridge/sam3\", self.z_response_callback)\n\n        self.z_thread = threading.Thread(target=self.znode.spin, daemon=True)\n        self.z_thread.start()\n\n    def image_callback(self, msg: Image):\n        self.current_frame = self.cv_bridge.imgmsg_to_cv2(msg, \"bgr8\")\n\n    def prompt_callback(self, msg: String):\n        prompt = msg.data\n        frame = self.current_frame\n        if not prompt or frame is None: return\n\n        rospy.loginfo(f\"Processing prompt: '{prompt}'\")\n\n        # Package the prompt and the compressed image for ZROS\n        msg_zros = {\n            \"prompt\": prompt,\n            \"zimgmsg\": self.zcv_bridge.cv2_to_zimgmsg(frame) # ZROS image message\n        }\n        self.z_pub.publish(msg_zros)\n\n    def z_response_callback(self, msg: dict):\n        status = msg[\"status\"]\n\n        if status == \"success\":\n            # ZROS image message to OpenCV\n            mask_object_cv2 = self.zcv_bridge.zimgmsg_to_cv2(msg[\"mask_object\"])\n            mask_objects_cv2 = self.zcv_bridge.zimgmsg_to_cv2(msg[\"mask_objects\"])\n\n            # OpenCV to ROS image message\n            mask_object_msg = self.cv_bridge.cv2_to_imgmsg(mask_object_cv2, \"mono8\")\n            mask_objects_msg = self.cv_bridge.cv2_to_imgmsg(mask_objects_cv2, \"mono8\")\n\n            self.mask_object_pub.publish(mask_object_msg)\n            self.mask_objects_pub.publish(mask_objects_msg)\n            rospy.loginfo(f\"Published masks (Conf: {msg['conf']:.2f})\")\n\n        elif status == \"no_detection\":\n            # Publish empty masks\n            empty_mask = np.zeros(self.current_frame.shape[:2], dtype=np.uint8)\n            empty_msg = self.cv_bridge.cv2_to_imgmsg(empty_mask, \"mono8\")\n\n            self.mask_object_pub.publish(empty_msg)\n            self.mask_objects_pub.publish(empty_msg)\n            rospy.loginfo(\"No objects detected.\")\n\n# Automatically boot up the isolated SAM3 environment using 'uv run'\ndef start_sam3():\n    cmd = [\"uv\", \"run\", \"--project\", \"sam3_bridge\", \"sam3_bridge/main.py\"]\n    return subprocess.Popen(cmd)\n\nif __name__ == '__main__':\n    start_sam3()\n    node = DetectObjects()\n    rospy.spin()\n</code></pre>"},{"location":"bridge_case/#2-the-modern-side-sam3-environment","title":"2. The Modern Side (SAM3 Environment)","text":"<p>This script runs in an isolated Python environment (managed automatically by <code>uv</code>) containing modern dependencies like <code>ultralytics</code> and PyTorch. Notice that this file has zero dependencies on ROS. It only talks to ZROS.</p> sam3_bridge/main.py<pre><code>import numpy as np, cv2\nfrom ultralytics.models.sam import SAM3SemanticPredictor\n\n# Import ZROS in the modern environment\nfrom zros import zNode, zCompressedCVBridge\n\nclass SAM3InferenceServer(zNode):\n    def __init__(self, imgsz=1092, half=False):\n        super().__init__(\"sam3_ros\")\n\n        self.bridge = zCompressedCVBridge()\n\n        # Load model\n        self.predictor = SAM3SemanticPredictor(\n            overrides=dict(\n                task=\"segment\",\n                mode=\"predict\",\n                model=\"sam3.pt\",\n                imgsz=imgsz,\n                half=half,\n                conf=0.5,\n                device=\"cuda\",\n                save=False\n            )\n        )\n        print(\"SAM3 ready\")\n\n        self.sub = self.create_subscriber(\"sam3_bridge/ros\", self.callback)\n        self.pub = self.create_publisher(\"sam3_bridge/sam3\")\n\n    def callback(self, msg: dict):\n        prompt = msg[\"prompt\"]\n        zimgmsg = msg[\"zimgmsg\"]\n\n        print(f\"Received prompt: {prompt}\")\n\n        # ZROS image message to OpenCV\n        frame = self.bridge.zimgmsg_to_cv2(zimgmsg)\n\n        # Run inference\n        results = self.predictor(source=frame, text=[prompt])[0]\n\n        response = {}\n        if results.boxes is None or len(results.boxes) == 0:\n            response[\"status\"] = \"no_detection\"\n        else:\n            # Extract highest confidence mask\n            idx = int(results.boxes.conf.argmax())\n            best_mask = (results.masks.data[idx].cpu().numpy() * 255).astype(\"uint8\")\n\n            # Combine all masks\n            all_masks = np.any(results.masks.data.cpu().numpy(), axis=0) * 255\n            all_masks = all_masks.astype(\"uint8\")\n\n            response[\"status\"] = \"success\"\n            response[\"conf\"] = float(results.boxes.conf[idx])\n\n            # Compress and send back via ZROS\n            response[\"mask_object\"] = self.bridge.cv2_to_zimgmsg(best_mask)\n            response[\"mask_objects\"] = self.bridge.cv2_to_zimgmsg(all_masks)\n\n        self.pub.publish(response)\n\nif __name__ == '__main__':\n    server = SAM3InferenceServer()\n    server.spin()\n</code></pre>"},{"location":"bridge_case/#example-sam3-ros-bridge","title":"Example: SAM3 ROS Bridge","text":"<p>To illustrate a complex integration, here is how ZROS bridges a modern SAM3 application with a legacy ROS1 environment.</p> <p>General Connections Both <code>rqt_graph</code> and <code>zros_status</code> show the general connections between the interconnected ROS nodes and the isolated SAM3 environment:  </p> <p>Terminal Execution This is the execution required to bring up the environment and perform object detection: </p> <p>Object Detection Output Here is the result of sending the prompt <code>'hand'</code>. The left <code>rqt_image_view</code> shows the raw camera feed, and the right view shows the generated mask from SAM3: </p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#1-setting-uv-the-python-project-manager","title":"1. Setting <code>UV</code>, the Python project manager","text":"<p>To facilitate the creation of virtual environments and manage Python packages and their dependencies we use a state of the art framework uv, its installation is straightforward and can be done via the following command:</p> macOS/LinuxWindows <p>Using <code>curl</code> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> Using <code>wget</code> <pre><code>wget -qO- https://astral.sh/uv/install.sh | sh\n</code></pre></p> <p>Use <code>irm</code> to download the script and execute it with <code>iex</code>: <pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></p>"},{"location":"installation/#2-install-zros","title":"2. Install ZROS","text":"From PyPIFrom Source <p>Recommended for most users</p> <p>Install the latest stable release from the Python Package Index (PyPI).</p> <pre><code>uv venv\nuv pip install zros\n</code></pre> <p>System Requirements</p> <p>ZROS requires Python 3.8 or higher. If you have a previous version, you can create a virtual environment with a compatible version using <code>uv venv --python 3.8</code> or higher.</p> <p>Recommended for developers</p> <p>Install the latest development version directly from the GitHub repository.</p> <pre><code>git clone https://github.com/juliodltv/zros.git\ncd zros\nuv sync\n</code></pre>"},{"location":"troubleshooting/","title":"ZROS Troubleshooting (ZROScore)","text":"<p>When you try to run <code>uv run zroscore</code> and you get an error like this:</p> <pre><code>zmq.error.ZMQError: Address already in use (addr='tcp://*:5555')\n</code></pre> <p>It means that ports <code>5555</code> or <code>5556</code> (which ZROS uses by default for subscribers and publishers) are occupied by a previous ZROS or Python process that wasn't closed correctly.</p>"},{"location":"troubleshooting/#commands-to-free-the-ports","title":"Commands to free the ports","text":"<p>You can use any of the following methods from the terminal to kill the process that is using the ports.</p>"},{"location":"troubleshooting/#method-1-using-fuser-recommended-and-fastest","title":"Method 1: Using <code>fuser</code> (Recommended and fastest)","text":"<p>This command will immediately find and kill the process using TCP ports 5555 or 5556.</p> <p><pre><code>fuser -k 5555/tcp\nfuser -k 5556/tcp\n</code></pre> (If it says permission denied, add <code>sudo</code> at the beginning: <code>sudo fuser -k 5555/tcp</code>)</p>"},{"location":"troubleshooting/#method-2-closing-all-zroscore-and-python-processes","title":"Method 2: Closing all ZROSCore and Python processes","text":"<p>If the error is caused specifically because the ZROS broker is still running in the background:</p> <pre><code>pkill -f zroscore\n</code></pre> <p>If your <code>pegasus_bridge.py</code> or <code>pegasus_viva.py</code> scripts got hung (zombies), you can force close all python processes (this will close all active simulations):</p> <pre><code>pkill -f python\n</code></pre>"},{"location":"troubleshooting/#method-3-using-lsof-to-find-the-pid-and-then-kill","title":"Method 3: Using <code>lsof</code> to find the PID and then <code>kill</code>","text":"<p>If you want to see exactly what is occupying the port before closing it:</p> <ol> <li> <p>Find the process ID (PID): <pre><code>lsof -i :5555\n</code></pre> (Look for the number in the <code>PID</code> column)</p> </li> <li> <p>Kill the process using its PID (replacing <code>&lt;PID&gt;</code> with the number): <pre><code>kill -9 &lt;PID&gt;\n</code></pre></p> </li> </ol>"},{"location":"usage/","title":"Usage Guide","text":"<p>ZROS mimics the ROS 2 workflow but uses ZeroMQ for communication.</p> <p>Note</p> <p>The following examples use <code>zCompressedCVBridge</code> and <code>cv2</code>. Make sure you have installed ZROS with Computer Vision support first: <code>uv pip install zros[cv2]</code></p>"},{"location":"usage/#create-a-publisher-publisherpy","title":"Create a Publisher (publisher.py)","text":"<pre><code>from zros import zNode, zCompressedCVBridge\nimport cv2\n\nclass CameraPublisher(zNode):\n    def __init__(self):\n        super().__init__(\"camera_pub\")\n        self.pub = self.create_publisher(\"video_topic\")\n        self.bridge = zCompressedCVBridge() # up to 30x more efficient bandwidth usage than zCvBridge\n        self.cap = cv2.VideoCapture(0)\n        self.create_timer(1/60, self.timer_callback)\n\n    def timer_callback(self):\n        ret, frame = self.cap.read()\n        if ret:\n            # msg is a dictionary\n            msg = {\n                \"zimgmsg\": self.bridge.cv2_to_zimgmsg(frame),\n                \"info\": \"My Camera Frame\"\n            }\n            self.pub.publish(msg)\n\nif __name__ == \"__main__\":\n    CameraPublisher().spin()\n</code></pre>"},{"location":"usage/#create-a-subscriber-subscriberpy","title":"Create a Subscriber (subscriber.py)","text":"<pre><code>from zros import zNode, zCompressedCVBridge\nimport cv2\n\nclass VideoSubscriber(zNode):\n    def __init__(self):\n        super().__init__(\"video_sub\")\n        self.bridge = zCompressedCVBridge()\n        self.create_subscriber(\"video_topic\", self.callback)\n\n    def callback(self, msg):\n        img = self.bridge.zimgmsg_to_cv2(msg[\"zimgmsg\"])\n        # info = msg[\"info\"]\n        # print(info)\n        cv2.imshow(\"Video\", img)\n        cv2.waitKey(1)\n\nif __name__ == \"__main__\":\n    VideoSubscriber().spin()\n</code></pre>"},{"location":"usage/#running-examples","title":"Running Examples","text":"<p>You can find another examples in the <code>examples/</code> directory.</p> <pre><code># Terminal 1\nuv run zroscore\n\n# Terminal 2\nuv run publisher.py\n\n# Terminal 3\nuv run subscriber.py\n</code></pre>"},{"location":"usage/#cli-tools","title":"CLI Tools","text":"<p>ZROS provides command-line tools to inspect and interact with the system.</p>"},{"location":"usage/#zros_status","title":"zros_status","text":"<p>Displays the currently active nodes and their topic connections (publishers and subscribers). It scans the network for a second and then prints the results hierarchically.</p> <pre><code>uv run zros_status\n</code></pre> <p>Output: <pre><code>- camera_pub\n    Publishers:\n      - video_topic\n- video_sub\n    Subscribers:\n      - video_topic\n</code></pre></p>"},{"location":"usage/#zros_pub","title":"zros_pub","text":"<p>Publishes a dictionary payload to a topic from the terminal.</p> <p>Syntax: <pre><code>uv run zros_pub &lt;TOPIC&gt; &lt;DICTIONARY_STRING&gt; [--rate &lt;HZ&gt;]\n</code></pre></p> <p>Example: <pre><code>uv run zros_pub /my_topic \"{'message': 'Hello from CLI', 'count': 42}\" --rate 0.5\n</code></pre> Note: The input keys and values should be between single quotes.</p> <p>Output: <pre><code>Publishing to /my_topic at 0.5 Hz: {'message': 'Hello from CLI', 'count': 42}\n</code></pre></p>"},{"location":"usage/#zros_echo","title":"zros_echo","text":"<p>Prints messages received on a topic to the console.</p> <p>Syntax: <pre><code>uv run zros_echo &lt;TOPIC&gt;\n</code></pre></p> <p>Example: <pre><code>uv run zros_echo /my_topic\n</code></pre></p> <p>Output: <pre><code>Subscribed to /my_topic\n{'message': 'Hello from CLI', 'count': 42}\n{'message': 'Hello from CLI', 'count': 42}\n...\n</code></pre></p>"}]}